{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOcNt9VnuVEKjWHpW+/Z0TO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Step 1: Get data\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BpSyJdcsqbSt","executionInfo":{"status":"ok","timestamp":1745980595053,"user_tz":300,"elapsed":439,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}},"outputId":"5b58f778-76a2-4c3e-d612-978b543ae402"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1_GpaYkp0nB","executionInfo":{"status":"ok","timestamp":1745967758264,"user_tz":300,"elapsed":455657,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}},"outputId":"2ca24220-d5b7-41f9-89c7-2c3c08bbcc9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thermal video FPS: 29.97002997002997\n","Normal video FPS: 29.97002997002997\n","Feature extraction completed and saved to video_features.csv\n"]}],"source":["import cv2\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","# Simple CNN model for feature extraction\n","class FeatureExtractorCNN(nn.Module):\n","    def __init__(self):\n","        super(FeatureExtractorCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.fc1 = nn.Linear(32 * 64 * 64, 128)  # Assuming input size is (3, 256, 256)\n","        self.fc2 = nn.Linear(128, 64)  # Reduce to 64 features, no risk classification\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu(self.conv1(x)))\n","        x = self.pool(self.relu(self.conv2(x)))\n","        x = x.view(-1, 32 * 64 * 64)\n","        x = self.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","google_drive_path = \"/content/drive/MyDrive/Colab Notebooks/Human Signals-Final Project/data/\"\n","\n","# Load videos\n","thermal_video_path = google_drive_path + 'aerial_data' + '/' + 'danger_running-thermal.MP4'\n","normal_video_path = google_drive_path + 'aerial_data' + '/' + 'danger_running-regular.MP4'\n","\n","thermal_cap = cv2.VideoCapture(thermal_video_path)\n","normal_cap = cv2.VideoCapture(normal_video_path)\n","\n","thermal_fps = thermal_cap.get(cv2.CAP_PROP_FPS)\n","normal_fps = normal_cap.get(cv2.CAP_PROP_FPS)\n","\n","print(f\"Thermal video FPS: {thermal_fps}\")\n","print(f\"Normal video FPS: {normal_fps}\")\n","\n","# Initialize model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = FeatureExtractorCNN().to(device)\n","model.eval()  # We assume the model is pre-trained, here for simplicity we just use random weights\n","\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor()\n","])\n","\n","results = []\n","\n","frame_idx = 0\n","while True:\n","    ret_thermal, frame_thermal = thermal_cap.read()\n","    ret_normal, frame_normal = normal_cap.read()\n","\n","    if not ret_thermal or not ret_normal:\n","        break\n","\n","    # Extract average temperature (assuming brightness = temperature proxy)\n","    gray_thermal = cv2.cvtColor(frame_thermal, cv2.COLOR_BGR2GRAY)\n","    avg_temperature = np.mean(gray_thermal)\n","\n","    # Estimate number of people using YOLO (if using YOLO for counting people)\n","    # Assuming YOLO is set up as previously mentioned for people counting\n","    gray_normal = cv2.cvtColor(frame_normal, cv2.COLOR_BGR2GRAY)\n","    _, thresh = cv2.threshold(gray_normal, 200, 255, cv2.THRESH_BINARY)\n","    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    avg_people_count = len(contours)\n","\n","    # Extract features using CNN\n","    input_frame = transform(frame_normal).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        features = model(input_frame)\n","        features = features.cpu().numpy().flatten()  # Flatten the feature vector to store\n","\n","    seconds_elapsed = frame_idx / normal_fps  # Assume thermal and normal videos are synchronized\n","\n","    results.append([seconds_elapsed, avg_temperature, avg_people_count] + list(features))\n","    frame_idx += 1\n","\n","# Save results to CSV\n","columns = [\"seconds_elapsed\", \"average_temperature\", \"average_people_count\"] + [f\"feature_{i+1}\" for i in range(64)]\n","output_df = pd.DataFrame(results, columns=columns)\n","output_df.to_csv(google_drive_path+'danger_running_video_features.csv', index=False)\n","\n","thermal_cap.release()\n","normal_cap.release()\n","\n","print(\"Feature extraction completed and saved to video_features.csv\")\n"]},{"cell_type":"code","source":["import cv2\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","# Simple CNN model for feature extraction\n","class FeatureExtractorCNN(nn.Module):\n","    def __init__(self):\n","        super(FeatureExtractorCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.fc1 = nn.Linear(32 * 64 * 64, 128)  # Assuming input size is (3, 256, 256)\n","        self.fc2 = nn.Linear(128, 64)  # Reduce to 64 features, no risk classification\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu(self.conv1(x)))\n","        x = self.pool(self.relu(self.conv2(x)))\n","        x = x.view(-1, 32 * 64 * 64)\n","        x = self.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","\n","def extract_aerial_features(label):\n","  activity_name , location = label.split(\"-\", 1)\n","  google_drive_path = \"/content/drive/MyDrive/Colab Notebooks/Human Signals-Final Project/data/\"\n","\n","  # Load videos\n","  thermal_video_path = google_drive_path + 'aerial_data' + '/' + activity_name + \"-thermal.MP4\"\n","  normal_video_path = google_drive_path + 'aerial_data' + '/' + activity_name + \"-regular.MP4\"\n","\n","  thermal_cap = cv2.VideoCapture(thermal_video_path)\n","  normal_cap = cv2.VideoCapture(normal_video_path)\n","\n","  thermal_fps = thermal_cap.get(cv2.CAP_PROP_FPS)\n","  normal_fps = normal_cap.get(cv2.CAP_PROP_FPS)\n","\n","  print(f\"Thermal video FPS: {thermal_fps}\")\n","  print(f\"Normal video FPS: {normal_fps}\")\n","\n","  # Initialize model\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  model = FeatureExtractorCNN().to(device)\n","  model.eval()  # We assume the model is pre-trained, here for simplicity we just use random weights\n","\n","  transform = transforms.Compose([\n","      transforms.ToPILImage(),\n","      transforms.Resize((256, 256)),\n","      transforms.ToTensor()\n","  ])\n","\n","  results = []\n","\n","  frame_idx = 0\n","  while True:\n","      ret_thermal, frame_thermal = thermal_cap.read()\n","      ret_normal, frame_normal = normal_cap.read()\n","\n","      if not ret_thermal or not ret_normal:\n","          break\n","\n","      # Extract average temperature (assuming brightness = temperature proxy)\n","      gray_thermal = cv2.cvtColor(frame_thermal, cv2.COLOR_BGR2GRAY)\n","      avg_temperature = np.mean(gray_thermal)\n","\n","      # Estimate number of people using YOLO (if using YOLO for counting people)\n","      # Assuming YOLO is set up as previously mentioned for people counting\n","      gray_normal = cv2.cvtColor(frame_normal, cv2.COLOR_BGR2GRAY)\n","      _, thresh = cv2.threshold(gray_normal, 200, 255, cv2.THRESH_BINARY)\n","      contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","      avg_people_count = len(contours)\n","\n","      # Extract features using CNN\n","      input_frame = transform(frame_normal).unsqueeze(0).to(device)\n","      with torch.no_grad():\n","          features = model(input_frame)\n","          features = features.cpu().numpy().flatten()  # Flatten the feature vector to store\n","\n","      seconds_elapsed = frame_idx / normal_fps  # Assume thermal and normal videos are synchronized\n","\n","      results.append([seconds_elapsed, avg_temperature, avg_people_count] + list(features))\n","      frame_idx += 1\n","\n","  # Save results to CSV\n","  columns = [\"seconds_elapsed\", \"average_temperature\", \"average_people_count\"] + [f\"feature_{i+1}\" for i in range(64)]\n","  output_df = pd.DataFrame(results, columns=columns)\n","  output_df['activity'] = activity_name\n","\n","\n","  thermal_cap.release()\n","  normal_cap.release()\n","\n","  return output_df\n","\n"],"metadata":{"id":"1AieJnGCxW8i","executionInfo":{"status":"ok","timestamp":1745980598036,"user_tz":300,"elapsed":28,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["labels = [\"danger_running-in_school\",\"play_basketball_alone-in_school\",\"play_basketball_with_kid-in_school\",\"running-in_school\",\"walking-in_school\",\"walking_at_7_foor-in_school\",\"walking_while_using_iphone-in_school\"]\n","all_aerial_features_list = []\n","for label in labels:\n","  aerial_features_df = extract_aerial_features(label)\n","  all_aerial_features_list.append(aerial_features_df)\n","\n","# Concatenate all DataFrames into one\n","all_aerial_features_df = pd.concat(all_aerial_features_list, ignore_index=True)\n","\n","google_drive_path = \"/content/drive/MyDrive/Colab Notebooks/Human Signals-Final Project/data/\"\n","all_aerial_features_df.to_csv(google_drive_path+'all_aerial_features.csv', index=False)\n","print(\"File saved as 'all_aerial_features.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9a3bPxwyj7J","executionInfo":{"status":"ok","timestamp":1745986085613,"user_tz":300,"elapsed":5483530,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}},"outputId":"91d8d86d-c09e-4a82-fd33-7022d3c5dc9b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Thermal video FPS: 29.97002997002997\n","Normal video FPS: 29.97002997002997\n","Thermal video FPS: 29.95891349007076\n","Normal video FPS: 29.97002997002997\n","Thermal video FPS: 29.967156249637792\n","Normal video FPS: 29.97002997002997\n","Thermal video FPS: 29.97002997002997\n","Normal video FPS: 29.97002997002997\n","Thermal video FPS: 29.97002997002997\n","Normal video FPS: 29.97002997002997\n","Thermal video FPS: 29.97002997002997\n","Normal video FPS: 29.962480844092934\n","Thermal video FPS: 29.97002997002997\n","Normal video FPS: 29.97002997002997\n","File saved as 'all_aerial_features.csv\n"]}]}]}