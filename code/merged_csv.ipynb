{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPapdkIjb2/yCc/d2icfSi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8-UTiMOhjlV","executionInfo":{"status":"ok","timestamp":1745999518606,"user_tz":300,"elapsed":610,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}},"outputId":"bfd95cf4-148a-4d0d-e0b2-6ff8e7d91b7a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","google_drive_path = \"/content/drive/MyDrive/Colab Notebooks/Human Signals-Final Project/data/\"\n","# Read the three CSV files\n","sensor_df = pd.read_csv(google_drive_path+'all_sensor_log_features.csv')\n","audio_df = pd.read_csv(google_drive_path+'all_audio_features.csv')\n","aerial_df = pd.read_csv(google_drive_path+'all_aerial_features.csv')\n","\n","# Ensure the required columns exist in each dataframe\n","required_columns = ['activity', 'seconds_elapsed']\n","for df in [sensor_df, audio_df, aerial_df]:\n","    assert all(col in df.columns for col in required_columns), \"Missing required columns!\"\n","\n","# Define a function to find the closest matching row based on activity and seconds_elapsed\n","def find_closest(row, target_df):\n","    candidates = target_df[target_df['activity'] == row['activity']]\n","    if candidates.empty:\n","        return None\n","    closest_idx = (candidates['seconds_elapsed'] - row['seconds_elapsed']).abs().idxmin()\n","    return candidates.loc[closest_idx]\n","\n","# Initialize lists to store the audio and aerial features\n","audio_features = []\n","aerial_features = []\n","\n","# Only select the relevant columns for aerial data\n","aerial_columns = ['average_temperature', 'average_people_count']\n","\n","# Iterate over each row in the sensor data to match audio and aerial features\n","for idx, row in sensor_df.iterrows():\n","    audio_row = find_closest(row, audio_df)\n","    aerial_row = find_closest(row, aerial_df)\n","\n","    if audio_row is not None:\n","        # Simply append all columns except 'activity' and 'seconds_elapsed' from the audio dataframe\n","        audio_features.append(audio_row.drop(['activity', 'seconds_elapsed']).values)\n","    else:\n","        audio_features.append([None] * (audio_df.shape[1] - 2))  # Exclude 'activity' and 'seconds_elapsed'\n","\n","    if aerial_row is not None:\n","        aerial_features.append(aerial_row[aerial_columns].values)\n","    else:\n","        aerial_features.append([None] * len(aerial_columns))\n","\n","# Add the extracted features back into the sensor dataframe\n","audio_feature_names = [f\"audio_{col}\" for col in audio_df.columns if col not in ['activity', 'seconds_elapsed']]\n","aerial_feature_names = [f\"aerial_{col}\" for col in aerial_columns]\n","\n","# Create dataframes for the expanded audio and aerial features\n","audio_df_expanded = pd.DataFrame(audio_features, columns=audio_feature_names)\n","aerial_df_expanded = pd.DataFrame(aerial_features, columns=aerial_feature_names)\n","\n","# Merge all the dataframes into one final dataframe\n","final_df = pd.concat([sensor_df, audio_df_expanded, aerial_df_expanded], axis=1)\n","\n","# Save the final merged dataframe to a new CSV file\n","final_df.to_csv(google_drive_path+'merged_features.csv', index=False)\n","\n","print(\"✅ Merge completed! The file has been saved as 'merged_features.csv'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOwN69lOi2Zz","executionInfo":{"status":"ok","timestamp":1745997429633,"user_tz":300,"elapsed":166914,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}},"outputId":"f53a53fb-0e6f-4542-badd-011aa0fab582"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Merge completed! The file has been saved as 'merged_features.csv'\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the CSV file\n","google_drive_path = \"/content/drive/MyDrive/Colab Notebooks/Human Signals-Final Project/data/\"\n","df = pd.read_csv(google_drive_path+'merged_features.csv')\n","\n","# Replace typo in 'activity' column\n","df['activity'] = df['activity'].replace('walking_at_7_foor', 'walking_at_7_floor')\n","\n","# Save back to CSV\n","df.to_csv(google_drive_path+'merged_features.csv', index=False)"],"metadata":{"id":"zRJsp3aPri0z","executionInfo":{"status":"ok","timestamp":1745999551913,"user_tz":300,"elapsed":890,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","\n","google_drive_path = \"/content/drive/MyDrive/Colab Notebooks/Human Signals-Final Project/data/\"\n","# Read the merged features CSV file\n","df = pd.read_csv(google_drive_path+'merged_features.csv')\n","\n","# Create a dictionary to map activity to label\n","activity_to_label = {\n","    'walking': 1,\n","    'running': 2,\n","    'play_basketball_alone': 3,\n","    'walking_at_7_floor': 4,\n","    'play_basketball_with_kid': 5,\n","    'walking_while_using_iphone': 6,\n","    'danger_running': 7\n","}\n","\n","# Add a new 'label' column based on the 'activity' column\n","df['label'] = df['activity'].map(activity_to_label)\n","\n","# Save the updated dataframe to a new CSV\n","df.to_csv(google_drive_path+'merged_features_with_labels.csv', index=False)\n","\n","print(\"✅ Labels added successfully! The file has been saved as 'merged_features_with_labels.csv'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfxNhRTdluMU","executionInfo":{"status":"ok","timestamp":1745999562631,"user_tz":300,"elapsed":1467,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}},"outputId":"5462fc15-4956-4fa5-c504-a5a737097cea"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Labels added successfully! The file has been saved as 'merged_features_with_labels.csv'\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","google_drive_path = \"/content/drive/MyDrive/Colab Notebooks/Human Signals-Final Project/data/\"\n","# Read the merged features with labels\n","df = pd.read_csv(google_drive_path+'balanced_merged_features.csv')\n","\n","# Count the number of records for each label\n","label_counts = df['label'].value_counts().sort_index()\n","\n","# Print the counts for each label\n","print(\"Record counts per label:\")\n","for label, count in label_counts.items():\n","    print(f\"Label {label}: {count} records\")\n","\n","# Print the total number of records\n","total_records = len(df)\n","print(f\"\\nTotal number of records: {total_records}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTOWNf6pmbq-","executionInfo":{"status":"ok","timestamp":1745999599248,"user_tz":300,"elapsed":123,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}},"outputId":"58492a90-9398-4f71-f0e6-0252880da0d1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Record counts per label:\n","Label 1: 2792 records\n","Label 2: 1233 records\n","Label 3: 1590 records\n","Label 4: 1612 records\n","Label 5: 3000 records\n","Label 6: 2499 records\n","Label 7: 1466 records\n","\n","Total number of records: 14192\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","\n","google_drive_path = \"/content/drive/MyDrive/Colab Notebooks/Human Signals-Final Project/data/\"\n","\n","df = pd.read_csv(google_drive_path+'merged_features_with_labels.csv')\n","\n","# Split the dataframe into two parts\n","label_5 = df[df['label'] == 5]\n","other_labels = df[df['label'] != 5]\n","\n","# Randomly sample 3000 records from label 5\n","label_5_sampled = label_5.sample(n=3000, random_state=42)  # random_state for reproducibility\n","\n","# Combine the sampled label 5 records with the other labels\n","balanced_df = pd.concat([label_5_sampled, other_labels], ignore_index=True)\n","\n","# Shuffle the combined dataframe\n","balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# Save the balanced data to a new CSV file\n","balanced_df.to_csv(google_drive_path+'balanced_merged_features.csv', index=False)\n","\n","print(f\"Original dataset: {len(df)} records\")\n","print(f\"Balanced dataset: {len(balanced_df)} records\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tFarDUrgn0wW","executionInfo":{"status":"ok","timestamp":1745999593283,"user_tz":300,"elapsed":604,"user":{"displayName":"Michael lai","userId":"13168535236366645027"}},"outputId":"72c7f3d1-4bef-41c9-8602-0d7cc0424087"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Original dataset: 24944 records\n","Balanced dataset: 14192 records\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"F1Zn7eNMhjUx"}}]}